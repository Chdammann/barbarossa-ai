<!DOCTYPE html>
<html lang="de">
<head>
<meta charset="utf-8" />
<meta name="viewport" content="width=device-width,initial-scale=1" />
<title>Test: Avatar Motion State Machine</title>
<style>
  body{margin:0;background:#000;color:#fff;font-family:Georgia,serif;overflow:hidden}
  h1{position:absolute;top:12px;width:100%;text-align:center;color:#e0b36b}
  #info{position:absolute;top:64px;width:100%;text-align:center;color:#ccc;font-size:0.95rem}
  #avatarCanvas{width:100%;height:100%;display:block}
  #micBtn{position:absolute;bottom:60px;left:50%;transform:translateX(-50%);width:80px;height:80px;border-radius:50%;background:#222;border:none;color:#fff;font-size:32px;cursor:pointer}
  #micBtn:hover{background:#444}
  #log{position:absolute;bottom:160px;left:50%;transform:translateX(-50%);color:#aaa;font-size:0.9rem;text-align:center;max-width:90%}
</style>
</head>
<body>
  <h1>Frag Friedrich â€” Motion Test</h1>
  <div id="info">TEST MODE: Klick den Button wie beschrieben (siehe Log). Kein Netzwerk.</div>
  <canvas id="avatarCanvas"></canvas>
  <div id="log">Status: ready</div>
  <button id="micBtn">ðŸŽ¤</button>

<script src="https://cdn.jsdelivr.net/npm/three@0.146.0/build/three.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/three@0.146.0/examples/js/loaders/GLTFLoader.js"></script>

<script>
/*
Minimal Test Version (no backend).
Purpose: test the motion/state behavior only.

State machine:
 - idle         : starting idle (slightly to avatar's right)
 - greet        : user pressed first time -> avatar lifts to frontal and speaks greeting
 - listen       : after greeting -> avatar stays frontal and "listens"
 - hm           : "Hmm... moment" -> slowly tilt to avatar-left
 - answer       : avatar slowly returns to frontal and speaks answer
 - return_idle  : after answer returns to idle tilt (avatar-right) and resets for next cycle

How to use in this test:
 1) Load page.
 2) Click mic button once -> greet (frontal).
 3) Click mic button second time -> simulate user question (enters hm phase).
 4) The test will then go to answer and then return to idle automatically.
You can repeat the cycle.

Tweaks:
 - baseRotY controls idle right tilt (negative = tilt to avatar-right).
 - hmTiltY controls how much to tilt to avatar-left during hm phase (positive = avatar-left).
*/

let state = "idle"; // idle, greet, listen, hm, answer, return_idle
const logEl = document.getElementById("log");
const micBtn = document.getElementById("micBtn");
let model = null;
let talking = false;

// --- rotation parameters (tweak here) ---
// Note: y-rotation: 0 = frontal. Negative values rotate to avatar-right, positive to avatar-left.
const baseRotY = -0.10;   // idle: slightly to avatar-right
const baseRotX = 0.00;
const greetRotY = 0.0;    // frontal
const greetRotX = 0.0;
const hmTiltY = +0.12;    // during "Hmm" tilt to avatar-left (positive)
const hmTiltX = +0.08;    // slight forward tilt during Hmm
const easeLerp = 0.04;    // how fast rotations lerp (0..1)
const riseDuration = 900; // ms used for timing debug only

// Three.js scene
const canvas = document.getElementById("avatarCanvas");
const scene = new THREE.Scene();
const camera = new THREE.PerspectiveCamera(30, window.innerWidth/window.innerHeight, 0.1, 1000);
camera.position.set(0,0,2.8);
const renderer = new THREE.WebGLRenderer({canvas, antialias:true});
renderer.setSize(window.innerWidth, window.innerHeight);
renderer.setPixelRatio(window.devicePixelRatio);
renderer.setClearColor(0x000000);

// lights (kept neutral so gold material remains bright)
scene.add(new THREE.DirectionalLight(0xffffff,1.4));
scene.add(new THREE.AmbientLight(0xffffff,0.6));
const frontLight = new THREE.PointLight(0xffffff,0.7);
frontLight.position.set(0,0.5,2);
scene.add(frontLight);

// loader
const loader = new THREE.GLTFLoader();
let loadingText = null;
loader.load('./avatar.glb',
  (gltf)=>{
    model = gltf.scene;
    // scale & center
    const box = new THREE.Box3().setFromObject(model);
    const size = box.getSize(new THREE.Vector3());
    const maxDim = Math.max(size.x,size.y,size.z);
    const scaleFactor = (1.5 / maxDim) * 0.9;
    model.scale.set(scaleFactor, scaleFactor, scaleFactor);
    const center = box.getCenter(new THREE.Vector3());
    model.position.sub(center);

    // set initial idle rotation explicitly (frontal slight right tilt)
    model.rotation.y = baseRotY;
    model.rotation.x = baseRotX;
    scene.add(model);
    log("Avatar geladen â€” State: idle (slight right)");
    animate();
  },
  undefined,
  (err)=>{
    console.error("Load err", err);
    log("Fehler: avatar.glb konnte nicht geladen werden (prÃ¼fe Pfad).");
  }
);

// helper log
function log(s){ logEl.textContent = "Status: " + s; console.log(s); }

// simple speak helper (may be blocked by browser autoplay rules)
// uses slow=false for normal text, slow=true for the "Hmm..." text
let maleVoice = null;
function loadVoices(){
  const voices = speechSynthesis.getVoices();
  maleVoice = voices.find(v=>/male|mann|stefan|markus/i.test(v.name)) || voices.find(v=>v.lang && v.lang.startsWith("de")) || voices[0]||null;
}
speechSynthesis.onvoiceschanged = loadVoices;
loadVoices();

function speak(text, slow=false){
  if(!maleVoice) loadVoices();
  if(!maleVoice) { console.log("No voice available:", text); return; }
  const u = new SpeechSynthesisUtterance(text);
  u.lang = "de-DE";
  u.voice = maleVoice;
  u.rate = slow ? 0.45 : 0.95;
  u.pitch = 0.6;
  u.volume = 0.85;
  u.onstart = ()=>{ talking = true; log("sprechen..."); };
  u.onend = ()=>{ talking = false; log("sprechen beendet"); };
  speechSynthesis.speak(u);
}

// animate loop
function animate(){
  requestAnimationFrame(animate);
  if(!model){ renderer.render(scene, camera); return; }

  // breathing / micro-movements always active
  const t = Date.now();
  const breathe = Math.sin(t*0.0015)*0.008 + Math.sin(t*0.0007)*0.004;
  model.position.y = breathe;

  // state-based target rotation
  let desiredY = baseRotY;
  let desiredX = baseRotX;

  if(state === "idle"){
    desiredY = baseRotY;
    desiredX = baseRotX;
  } else if(state === "greet"){
    desiredY = greetRotY;
    desiredX = greetRotX;
  } else if(state === "listen"){
    desiredY = greetRotY; // remain frontal while listening
    desiredX = greetRotX;
  } else if(state === "hm"){
    // slowly tilt to avatar-left relative to current (we store start rotation on hm start)
    desiredY = hmStartRotY + hmTiltY;
    desiredX = hmStartRotX + hmTiltX;
  } else if(state === "answer"){
    desiredY = 0.0; // frontal while answering
    desiredX = 0.0;
  } else if(state === "return_idle"){
    desiredY = baseRotY;
    desiredX = baseRotX;
  }

  // smooth lerp each frame
  model.rotation.y = THREE.MathUtils.lerp(model.rotation.y, desiredY, easeLerp);
  model.rotation.x = THREE.MathUtils.lerp(model.rotation.x, desiredX, easeLerp);

  // tiny sway for liveliness
  model.rotation.z = Math.sin(t*0.0012)*0.004;

  renderer.render(scene, camera);
}

// --- mic button behavior (TEST MODE) ---
// We'll use a deterministic click sequence to test the states.
// Sequence: idle -> (click 1) greet -> (click 2) listen -> (click 3) hm -> (automatic) answer -> return_idle -> idle
let hmStartRotX = 0, hmStartRotY = 0;

micBtn.addEventListener('click', ()=>{
  if(!model){ log("Avatar noch nicht geladen"); return; }

  if(state === "idle"){
    // First click: greet (frontal), speak greeting, then set state to listen
    state = "greet";
    log("greet â€” richtet sich frontal und begrÃ¼ÃŸt");
    targetRotY = 0; targetRotX = 0;
    speak("Seid gegrÃ¼ÃŸt, mein Freund. Sprecht, was begehrt Ihr?");
    // after greeting finished: move to listen (wait for user to click to simulate question)
    // We can't rely on exact speechSynthesis timing in every browser, so use onend to progress:
    // onend will set talking=false; so next click will go to listen/hm as appropriate.
    greeted = true;
    return;
  }

  // If greeted and not currently listening or in hm or answer, next click simulates user starting to speak
  if(greeted && state !== "hm" && state !== "answer" && !talking){
    // Simulate: user speaks -> we enter hm-phase
    state = "listen"; // remain frontal (listening)
    log("listen â€” Avatar bleibt frontal (Frageaufnahme simuliert). Klick noch einmal, um 'Hmm' zu starten.");
    return;
  }

  // If we are in listen and user clicks again -> start hm-phase
  if(state === "listen" && !talking){
    state = "hm";
    // record start rotation to interpolate from
    hmStartRotX = model.rotation.x;
    hmStartRotY = model.rotation.y;
    hmStartRotX = hmStartRotX; hmStartRotY = hmStartRotY;
    log("hm â€” 'Hmm... einen Moment' (neigt sich langsam nach links)");
    // speak short 'hmm' slowly
    speak("Hmmmmmmâ€¦ einen Moment", true);

    // After hmDuration, go to answer (simulate server answer). Use setTimeout to emulate network + thinking.
    setTimeout(()=>{
      state = "answer";
      log("answer â€” richtet sich langsam frontal auf und spricht Antwort (simuliert)");
      // simulated answer text (dummy)
      speak("Dies ist eine Testantwort. Die Bewegungen sollten nun sichtbar sein.");
      // After answer finishes (we monitor talking via speak onend), move to return_idle:
      const checkEnd = setInterval(()=>{
        if(!talking){
          clearInterval(checkEnd);
          state = "return_idle";
          log("return_idle â€” RÃ¼ckkehr in Ausgangsposition (slightly right)");
          // after some time to allow lerp back, set state idle and reset greeted so next click greets again
          setTimeout(()=>{
            state = "idle";
            greeted = false;
            log("idle â€” bereit fÃ¼r neuen Durchgang (nÃ¤chster Klick lÃ¶st BegrÃ¼ÃŸung aus)");
          }, 900);
        }
      }, 120);
    }, 1200 + hmDuration/6); // slight wait to make hm visible
    return;
  }

  // fallback: if clicked during answer/talking, ignore
  if(state === "answer" || talking){
    log("WÃ¤hrend Antwort: klick ignoriert (warte bis Antwort endet)");
    return;
  }
});

// resize
window.addEventListener('resize', ()=>{
  camera.aspect = window.innerWidth/window.innerHeight;
  camera.updateProjectionMatrix();
  renderer.setSize(window.innerWidth, window.innerHeight);
});

// initial log
log("ready â€” Click mic: 1=greet, 2=listen, 3=hm -> auto answer -> return idle");

</script>
</body>
</html>
